{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8EvpTyiNNal"
   },
   "source": [
    "# Wide Data For Geographic Information\n",
    "\n",
    "The data in this competition is connected through both location and time.  Many notebooks make good use of the time series aspect of this competition, but I have not see n any that try to make geographic connections between the 65 x-y/direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COHzD8YtNO-m",
    "outputId": "8856819c-15b9-47a3-fb98-0bf0a6115135"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.0)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.10.2-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
      "Collecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (1.4.47)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.10.2 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-25T11:07:22.506314Z",
     "iopub.status.busy": "2022-03-25T11:07:22.505973Z",
     "iopub.status.idle": "2022-03-25T11:07:28.430099Z",
     "shell.execute_reply": "2022-03-25T11:07:28.429399Z",
     "shell.execute_reply.started": "2022-03-25T11:07:22.506237Z"
    },
    "id": "yvuSNXlaNNao"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "mRHa-_wSNeFG",
    "outputId": "21669f5a-f751-4c23-8f1f-9129c3c88634"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-a9563b10-98b7-4543-84bf-dc474f9ce5e1\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-a9563b10-98b7-4543-84bf-dc474f9ce5e1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train.csv to train.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "1PyHfhG0NkWj",
    "outputId": "22feaa02-7cf1-48bb-9d08-1aa2c11ddb59"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-155d8686-b0e1-4dfa-8ed7-770bf4606645\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-155d8686-b0e1-4dfa-8ed7-770bf4606645\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test.csv to test.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "l6SbCdg-NlNZ",
    "outputId": "c2493d33-f7f4-4862-9fec-c40e8ad4f717"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-8b090b81-49d1-4c2f-899f-c20643a4d9d7\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-8b090b81-49d1-4c2f-899f-c20643a4d9d7\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sample_submission.csv to sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T11:07:28.431946Z",
     "iopub.status.busy": "2022-03-25T11:07:28.431717Z",
     "iopub.status.idle": "2022-03-25T11:07:31.071484Z",
     "shell.execute_reply": "2022-03-25T11:07:31.070778Z",
     "shell.execute_reply.started": "2022-03-25T11:07:28.431912Z"
    },
    "id": "KLgYNbrgNNap"
   },
   "outputs": [],
   "source": [
    "train_y = pd.read_csv('train.csv')\n",
    "test_y =  pd.read_csv('test.csv')\n",
    "ss = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "\n",
    "#Scaling the TARGET values back by 100 for NN learning \n",
    "TARGET = 'congestion'\n",
    "train_y[TARGET] = train_y[TARGET] / 100\n",
    "test_y[TARGET] = 0\n",
    "\n",
    "#Turning time to DateTime\n",
    "train_y['time'] = pd.to_datetime(train_y['time'])\n",
    "test_y['time'] = pd.to_datetime(test_y['time'])\n",
    "ss['time'] = test_y['time']\n",
    "\n",
    "#Combing all location features \n",
    "train_y['xydir'] = train_y['x'].astype(str) + '_' + train_y['y'].astype(str) + train_y['direction']\n",
    "test_y['xydir'] = test_y['x'].astype(str) + '_' + test_y['y'].astype(str) + test_y['direction']\n",
    "ss['xydir'] = test_y['xydir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T11:07:31.073073Z",
     "iopub.status.busy": "2022-03-25T11:07:31.072836Z",
     "iopub.status.idle": "2022-03-25T11:07:31.40776Z",
     "shell.execute_reply": "2022-03-25T11:07:31.406964Z",
     "shell.execute_reply.started": "2022-03-25T11:07:31.073041Z"
    },
    "id": "Q_SlVnwQNNaq"
   },
   "outputs": [],
   "source": [
    "#Turning the data from `long` to `wide`\n",
    "train_y = train_y[['time','xydir','congestion']].set_index(['time','xydir'])\n",
    "train_y = train_y.unstack()\n",
    "train_y.columns = train_y.columns.map(lambda x: x[1])\n",
    "train_y = train_y.reset_index()\n",
    "\n",
    "test_y = test_y[['time','xydir','congestion']].set_index(['time','xydir'])\n",
    "test_y = test_y.unstack()\n",
    "test_y.columns = test_y.columns.map(lambda x: x[1])\n",
    "test_y = test_y.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "execution": {
     "iopub.execute_input": "2022-03-25T11:07:36.725661Z",
     "iopub.status.busy": "2022-03-25T11:07:36.724866Z",
     "iopub.status.idle": "2022-03-25T11:07:36.759988Z",
     "shell.execute_reply": "2022-03-25T11:07:36.759328Z",
     "shell.execute_reply.started": "2022-03-25T11:07:36.725611Z"
    },
    "id": "hf0KgJL0NNar",
    "outputId": "13ff2c82-5fa5-4319-fc1c-679772b98351"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c71e534f-cddf-4542-96ff-9fd4c2e0d8a4\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>0_0EB</th>\n",
       "      <th>0_0NB</th>\n",
       "      <th>0_0SB</th>\n",
       "      <th>0_1EB</th>\n",
       "      <th>0_1NB</th>\n",
       "      <th>0_1SB</th>\n",
       "      <th>0_1WB</th>\n",
       "      <th>0_2EB</th>\n",
       "      <th>0_2NB</th>\n",
       "      <th>...</th>\n",
       "      <th>2_2SB</th>\n",
       "      <th>2_2SE</th>\n",
       "      <th>2_2SW</th>\n",
       "      <th>2_2WB</th>\n",
       "      <th>2_3EB</th>\n",
       "      <th>2_3NB</th>\n",
       "      <th>2_3NE</th>\n",
       "      <th>2_3SB</th>\n",
       "      <th>2_3SW</th>\n",
       "      <th>2_3WB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-04-01 00:00:00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-04-01 00:20:00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1991-04-01 00:40:00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1991-04-01 01:00:00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1991-04-01 01:20:00</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.46</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c71e534f-cddf-4542-96ff-9fd4c2e0d8a4')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c71e534f-cddf-4542-96ff-9fd4c2e0d8a4 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c71e534f-cddf-4542-96ff-9fd4c2e0d8a4');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                 time  0_0EB  0_0NB  0_0SB  0_1EB  0_1NB  0_1SB  0_1WB  0_2EB  \\\n",
       "0 1991-04-01 00:00:00    0.7   0.49   0.24   0.18   0.60   0.58   0.26   0.31   \n",
       "1 1991-04-01 00:20:00    0.7   0.49   0.24   0.26   0.64   0.55   0.57   0.41   \n",
       "2 1991-04-01 00:40:00    0.7   0.49   0.24   0.31   0.51   0.57   0.91   0.42   \n",
       "3 1991-04-01 01:00:00    0.7   0.49   0.24   0.36   0.51   0.46   0.49   0.39   \n",
       "4 1991-04-01 01:20:00    0.7   0.49   0.24   0.29   0.53   0.83   0.62   0.36   \n",
       "\n",
       "   0_2NB  ...  2_2SB  2_2SE  2_2SW  2_2WB  2_3EB  2_3NB  2_3NE  2_3SB  2_3SW  \\\n",
       "0   0.49  ...   0.36   0.51   0.47   0.51   0.39   0.64    0.3   0.70   0.29   \n",
       "1   0.40  ...   0.10   0.51   0.50   0.58   0.33   0.67    0.3   0.80   0.29   \n",
       "2   0.41  ...   0.32   0.51   0.49   0.63   0.33   0.64    0.3   0.79   0.29   \n",
       "3   0.44  ...   0.60   0.51   0.49   0.52   0.33   0.33    0.3   0.77   0.29   \n",
       "4   0.46  ...   0.43   0.51   0.49   0.50   0.33   0.50    0.3   0.79   0.29   \n",
       "\n",
       "   2_3WB  \n",
       "0   0.26  \n",
       "1   0.57  \n",
       "2   0.48  \n",
       "3   0.44  \n",
       "4   0.44  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T15:20:02.352892Z",
     "iopub.status.busy": "2022-03-24T15:20:02.35259Z",
     "iopub.status.idle": "2022-03-24T15:20:04.825325Z",
     "shell.execute_reply": "2022-03-24T15:20:04.824544Z",
     "shell.execute_reply.started": "2022-03-24T15:20:02.352858Z"
    },
    "id": "rBHXMz3eNNar"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Feature Engineering\n",
    "'''\n",
    "#Feature lists\n",
    "RAW_FEATURES = [feat for feat in train_y.columns if feat != 'time']\n",
    "HM_MOVING_MEDIANS = [f'HMMM_{feat}' for feat in RAW_FEATURES] #For daily moving medians\n",
    "DHM_MOVING_MEDIANS = [f'DHMMM_{feat}' for feat in RAW_FEATURES] #For weekly moving medians\n",
    "ONE_HOUR_MEAN = ['1hm'+feat for feat in RAW_FEATURES] # for mean over the hour\n",
    "\n",
    "#Creating day, hour, and minute features\n",
    "train_y['day'] = train_y.time.dt.day % 7\n",
    "train_y['hour'] =train_y.time.dt.hour\n",
    "train_y['minute'] = train_y.time.dt.minute\n",
    "train_y['dhm'] = train_y['day'].astype(str) + '_' + train_y['hour'].astype(str) + '_' + train_y['minute'].astype(str)\n",
    "train_y['hm'] = train_y['hour'].astype(str) + '_' + train_y['minute'].astype(str)\n",
    "train_y['day'] = train_y['day'] / 7\n",
    "train_y['hour'] =train_y['hour'] / 24\n",
    "train_y['minute'] = train_y['minute']/40\n",
    "\n",
    "#1) Row wise mean, median, var, kurtosis\n",
    "train_y['row_kurtosis'] = train_y[RAW_FEATURES].kurtosis(axis=1)\n",
    "train_y['row_mean'] = train_y[RAW_FEATURES].mean(axis=1)\n",
    "train_y['row_median'] = train_y[RAW_FEATURES].median(axis=1)\n",
    "train_y['row_var'] = train_y[RAW_FEATURES].var(axis=1)\n",
    "\n",
    "#2) moving median\n",
    "#help from https://stackoverflow.com/questions/36969174/pandas-average-value-for-the-past-n-days\n",
    "#train_y[HM_MOVING_MEDIANS] = train_y.groupby('hm')[RAW_FEATURES].apply(lambda x: x.shift().expanding(min_periods=1).median())\n",
    "train_y[HM_MOVING_MEDIANS] = train_y.groupby('hm')[RAW_FEATURES].apply(lambda x: x.expanding(min_periods=1).median())\n",
    "\n",
    "#3) weekly moving median\n",
    "train_y[DHM_MOVING_MEDIANS] = train_y.groupby('dhm')[RAW_FEATURES].apply(lambda x: x.expanding(min_periods=1).median())\n",
    "\n",
    "#4) 1 hour mean\n",
    "train_y[ONE_HOUR_MEAN] = train_y[RAW_FEATURES].rolling(3).mean().fillna(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T15:20:04.827751Z",
     "iopub.status.busy": "2022-03-24T15:20:04.827462Z",
     "iopub.status.idle": "2022-03-24T15:20:04.941521Z",
     "shell.execute_reply": "2022-03-24T15:20:04.940746Z",
     "shell.execute_reply.started": "2022-03-24T15:20:04.827717Z"
    },
    "id": "Dz--jVFFNNas"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Creating train_X and test_X\n",
    "----------------------------\n",
    "\n",
    "train_X is the lag -1 day features and train_y is just the present day\n",
    "test_X, also, is one day behind test_y\n",
    "'''\n",
    "train_X = train_y[['time']].copy()\n",
    "train_X['time'] = train_X.time - pd.Timedelta(days=1)\n",
    "train_X = pd.merge(train_X, train_y, on='time', how='left')\n",
    "\n",
    "test_X = test_y[['time']].copy()\n",
    "test_X['time'] = test_X.time - pd.Timedelta(days=1)\n",
    "test_X = pd.merge(test_X, train_y, on='time', how='left')\n",
    "\n",
    "#Discarding all Nan rows from train_X, train_y\n",
    "missing = train_X['0_0EB'].isnull()\n",
    "train_X = train_X[~missing].reset_index(drop=True)\n",
    "train_y = train_y[~missing].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T15:20:04.943366Z",
     "iopub.status.busy": "2022-03-24T15:20:04.943049Z",
     "iopub.status.idle": "2022-03-24T15:20:04.979094Z",
     "shell.execute_reply": "2022-03-24T15:20:04.978097Z",
     "shell.execute_reply.started": "2022-03-24T15:20:04.943327Z"
    },
    "id": "2SFxHQTkNNat"
   },
   "outputs": [],
   "source": [
    "#Use train time stamps 1 week before test as validation data\n",
    "val_times = test_y.time - pd.Timedelta(days=7) \n",
    "val_msk = train_X.time.isin(val_times)\n",
    "\n",
    "val_X = train_X[val_msk].copy()\n",
    "val_y = train_y[val_msk].copy()\n",
    "\n",
    "train_X = train_X[~val_msk].copy()\n",
    "train_y = train_y[~val_msk].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T15:20:04.980975Z",
     "iopub.status.busy": "2022-03-24T15:20:04.980641Z",
     "iopub.status.idle": "2022-03-24T15:20:04.992221Z",
     "shell.execute_reply": "2022-03-24T15:20:04.991412Z",
     "shell.execute_reply.started": "2022-03-24T15:20:04.980935Z"
    },
    "id": "uKW7UoJaNNat"
   },
   "outputs": [],
   "source": [
    "def create_vanilla_nn(FEATURES, RAW_FEATURES, DROPOUT_LEVEL, FIRST_DROPOUT, NUM_NEURONS, NUM_HIDDEN_LAYERS, lr):\n",
    "    INPUT_SHAPE, OUTPUT_SHAPE = len(FEATURES), len(RAW_FEATURES) \n",
    "    inp = tf.keras.layers.Input(shape = (INPUT_SHAPE,) )\n",
    "\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(FIRST_DROPOUT)(x)\n",
    "\n",
    "    for i in range(NUM_HIDDEN_LAYERS):\n",
    "        x = tf.keras.layers.Dense(NUM_NEURONS[i], activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(DROPOUT_LEVEL)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(OUTPUT_SHAPE, activation= 'sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inp, outputs= x)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=tf.keras.losses.MeanSquaredError())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2INO__9NNau"
   },
   "source": [
    "Below is my optuna trial to find both optimal features and optimal hyperparameters for the neural network.  Uncomment if you want to perform this yourself.  It takes around 1 hour for 100 trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "execution": {
     "iopub.execute_input": "2022-03-24T15:20:04.994288Z",
     "iopub.status.busy": "2022-03-24T15:20:04.993801Z",
     "iopub.status.idle": "2022-03-24T15:20:05.004961Z",
     "shell.execute_reply": "2022-03-24T15:20:05.004108Z",
     "shell.execute_reply.started": "2022-03-24T15:20:04.994244Z"
    },
    "id": "61W_TynwNNav",
    "outputId": "e42e9ccf-e548-4eda-bcc6-4bc15e7226a6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\ndef objective(trial):\\n    ###################################\\n    # Generate our trial model.\\n    ###################################\\n    #Model Architecture specifications\\n    NN_params = {}\\n    FEATURES = RAW_FEATURES.copy()\\n    if trial.suggest_categorical(\"hm_mm\", [True, False]):\\n        FEATURES += HM_MOVING_MEDIANS\\n    if trial.suggest_categorical(\"dhm_mm\", [True, False]):\\n        FEATURES += DHM_MOVING_MEDIANS\\n    if trial.suggest_categorical(\"one_hour_mean\", [True, False]):\\n        FEATURES += ONE_HOUR_MEAN\\n    if trial.suggest_categorical(\"row_stats\", [True, False]):\\n        FEATURES += [\\'row_kurtosis\\', \\'row_mean\\', \\'row_median\\', \\'row_var\\']\\n    if trial.suggest_categorical(\"time_base\", [True, False]):\\n        FEATURES += [\\'day\\', \\'hour\\', \\'minute\\']\\n    NN_params[\\'FEATURES\\'] = FEATURES\\n    NN_params[\\'RAW_FEATURES\\'] = RAW_FEATURES\\n    NN_params[\"DROPOUT_LEVEL\"] = trial.suggest_float(\"dropout\", 0.00,0.6)\\n    NN_params[\"FIRST_DROPOUT\"] = trial.suggest_float(\"first_dropout\", 0.00,0.9)\\n    NN_params[\"NUM_HIDDEN_LAYERS\"] = trial.suggest_int(\"depth\", 1,8)\\n    NN_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\\n\\n    num_neurons = []\\n    for i in range(NN_params[\"NUM_HIDDEN_LAYERS\"]):\\n        if i==0:\\n            num_neurons.append(trial.suggest_int(f\"num_neurons_l{i}\", len(RAW_FEATURES),5000))\\n        else:\\n            num_neurons.append(trial.suggest_int(f\"num_neurons_l{i}\", len(RAW_FEATURES), num_neurons[-1]))\\n    NN_params[\"NUM_NEURONS\"] = num_neurons\\n    \\n    model = create_vanilla_nn(**NN_params)\\n    BATCH_SIZE = 256\\n    ES = tf.keras.callbacks.EarlyStopping(\\n            monitor=\\'val_loss\\', min_delta=0, patience=20, restore_best_weights=True)\\n\\n    H = model.fit(train_X[NN_params[\"FEATURES\"]], train_y[RAW_FEATURES], batch_size= BATCH_SIZE, epochs=200, \\n              validation_split=.05, callbacks = [ES], verbose = 0)\\n    \\n    \\n        #Val Score\\n    val_preds = model.predict(val_X[NN_params[\"FEATURES\"]], batch_size=1000)\\n    score = 100 * np.mean(np.abs(val_y[RAW_FEATURES].values - val_preds))\\n    \\n    \\n    #Stopping Memory Leaks\\n    del model\\n    tf.keras.backend.clear_session()\\n\\n    return score\\nstudy = optuna.create_study(direction=\"minimize\")\\nstudy.optimize(objective, n_trials=100)\\n\\nprint(\"Study statistics: \")\\nprint(\"  Number of finished trials: \", len(study.trials))\\n\\nprint(\"Best trial:\")\\ntrial = study.best_trial\\n\\nprint(\"  Value: \", trial.value)\\n\\nprint(\"  Params: \")\\nfor key, value in trial.params.items():\\n    print(\"    {}: {}\".format(key, value))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def objective(trial):\n",
    "    ###################################\n",
    "    # Generate our trial model.\n",
    "    ###################################\n",
    "    #Model Architecture specifications\n",
    "    NN_params = {}\n",
    "    FEATURES = RAW_FEATURES.copy()\n",
    "    if trial.suggest_categorical(\"hm_mm\", [True, False]):\n",
    "        FEATURES += HM_MOVING_MEDIANS\n",
    "    if trial.suggest_categorical(\"dhm_mm\", [True, False]):\n",
    "        FEATURES += DHM_MOVING_MEDIANS\n",
    "    if trial.suggest_categorical(\"one_hour_mean\", [True, False]):\n",
    "        FEATURES += ONE_HOUR_MEAN\n",
    "    if trial.suggest_categorical(\"row_stats\", [True, False]):\n",
    "        FEATURES += ['row_kurtosis', 'row_mean', 'row_median', 'row_var']\n",
    "    if trial.suggest_categorical(\"time_base\", [True, False]):\n",
    "        FEATURES += ['day', 'hour', 'minute']\n",
    "    NN_params['FEATURES'] = FEATURES\n",
    "    NN_params['RAW_FEATURES'] = RAW_FEATURES\n",
    "    NN_params[\"DROPOUT_LEVEL\"] = trial.suggest_float(\"dropout\", 0.00,0.6)\n",
    "    NN_params[\"FIRST_DROPOUT\"] = trial.suggest_float(\"first_dropout\", 0.00,0.9)\n",
    "    NN_params[\"NUM_HIDDEN_LAYERS\"] = trial.suggest_int(\"depth\", 1,8)\n",
    "    NN_params[\"lr\"] = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "\n",
    "    num_neurons = []\n",
    "    for i in range(NN_params[\"NUM_HIDDEN_LAYERS\"]):\n",
    "        if i==0:\n",
    "            num_neurons.append(trial.suggest_int(f\"num_neurons_l{i}\", len(RAW_FEATURES),5000))\n",
    "        else:\n",
    "            num_neurons.append(trial.suggest_int(f\"num_neurons_l{i}\", len(RAW_FEATURES), num_neurons[-1]))\n",
    "    NN_params[\"NUM_NEURONS\"] = num_neurons\n",
    "    \n",
    "    model = create_vanilla_nn(**NN_params)\n",
    "    BATCH_SIZE = 256\n",
    "    ES = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', min_delta=0, patience=20, restore_best_weights=True)\n",
    "\n",
    "    H = model.fit(train_X[NN_params[\"FEATURES\"]], train_y[RAW_FEATURES], batch_size= BATCH_SIZE, epochs=200, \n",
    "              validation_split=.05, callbacks = [ES], verbose = 0)\n",
    "    \n",
    "    \n",
    "        #Val Score\n",
    "    val_preds = model.predict(val_X[NN_params[\"FEATURES\"]], batch_size=1000)\n",
    "    score = 100 * np.mean(np.abs(val_y[RAW_FEATURES].values - val_preds))\n",
    "    \n",
    "    \n",
    "    #Stopping Memory Leaks\n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    return score\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-03-24T15:20:05.006857Z",
     "iopub.status.busy": "2022-03-24T15:20:05.006548Z",
     "iopub.status.idle": "2022-03-24T15:22:52.404057Z",
     "shell.execute_reply": "2022-03-24T15:22:52.403244Z",
     "shell.execute_reply.started": "2022-03-24T15:20:05.006803Z"
    },
    "id": "wmsRxeQINNax",
    "outputId": "3418f8b5-966f-4861-b69f-5d8324d49dae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 121ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "FOLD 1 of 10: 5.453543288509051\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "FOLD 2 of 10: 5.4443634030146475\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "FOLD 3 of 10: 5.45480341592915\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "FOLD 4 of 10: 5.502592556013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12df9f3f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "FOLD 5 of 10: 5.4598078444218014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12df4ed040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "FOLD 6 of 10: 5.455464735194148\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "FOLD 7 of 10: 5.475489271298432\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "FOLD 8 of 10: 5.458706929362737\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "FOLD 9 of 10: 5.426302925185261\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "FOLD 10 of 10: 5.487611963555344\n",
      "Cumulative validation: 5.427126332837292\n"
     ]
    }
   ],
   "source": [
    "FEATURES = RAW_FEATURES.copy() + HM_MOVING_MEDIANS + ONE_HOUR_MEAN + ['row_kurtosis', 'row_mean', 'row_median', 'row_var'] + ['day', 'hour', 'minute']\n",
    "params = {'FEATURES': FEATURES, \n",
    "          'RAW_FEATURES': RAW_FEATURES, \n",
    "          'DROPOUT_LEVEL': 0.12292871613987645, \n",
    "          'FIRST_DROPOUT': 0.4302064801787497, \n",
    "          'NUM_NEURONS': [4526], \n",
    "          'NUM_HIDDEN_LAYERS': 1,\n",
    "          'lr': 0.0030322842074454745, }\n",
    "\n",
    "#Run the model 10 times and average preds\n",
    "n_folds = 10\n",
    "val_cum = 0\n",
    "for i in range(n_folds):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = create_vanilla_nn(**params)\n",
    "    BATCH_SIZE = 256\n",
    "    ES = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', min_delta=0, patience=20, restore_best_weights=True)\n",
    "\n",
    "    H = model.fit(train_X[FEATURES], train_y[RAW_FEATURES], batch_size= BATCH_SIZE, epochs=200, \n",
    "              validation_data=(val_X[FEATURES], val_y[RAW_FEATURES]), callbacks = [ES], verbose=0)\n",
    "    val_preds = model.predict(val_X[FEATURES], batch_size=1000)\n",
    "    test_y[RAW_FEATURES] += model.predict(test_X[FEATURES]) / n_folds      \n",
    "\n",
    "    #Val Score\n",
    "    val_cum += val_preds / n_folds\n",
    "    val_score = 100 * np.mean(np.abs(val_y[RAW_FEATURES].values - val_preds))\n",
    "    print(f'FOLD {i+1} of {n_folds}: {val_score}')\n",
    "\n",
    "cumulative_score = 100 * np.mean(np.abs(val_y[RAW_FEATURES].values - val_cum))\n",
    "print(f'Cumulative validation: {cumulative_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T15:22:52.40671Z",
     "iopub.status.busy": "2022-03-24T15:22:52.406293Z",
     "iopub.status.idle": "2022-03-24T15:22:52.420748Z",
     "shell.execute_reply": "2022-03-24T15:22:52.419988Z",
     "shell.execute_reply.started": "2022-03-24T15:22:52.406657Z"
    },
    "id": "DRDQblndNNay"
   },
   "outputs": [],
   "source": [
    "#Getting Predictions back to regular shape from `wide`\n",
    "test_y = pd.melt(test_y, id_vars = 'time', value_vars=RAW_FEATURES, var_name = 'xydir',value_name = 'congestion')\n",
    "ss = pd.merge(ss[['row_id', 'time','xydir']], test_y, on = ['time','xydir'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-24T15:22:52.422457Z",
     "iopub.status.busy": "2022-03-24T15:22:52.422106Z",
     "iopub.status.idle": "2022-03-24T15:22:52.749159Z",
     "shell.execute_reply": "2022-03-24T15:22:52.748336Z",
     "shell.execute_reply.started": "2022-03-24T15:22:52.422421Z"
    },
    "id": "raPqucNgNNay"
   },
   "outputs": [],
   "source": [
    "#####################\n",
    "#Post Processing\n",
    "#####################\n",
    "#Idea from https://www.kaggle.com/code/ambrosm/tpsmar22-generalizing-the-special-values\n",
    "train_melt = pd.melt(train_y, id_vars = 'time', value_vars=RAW_FEATURES, var_name = 'xydir',value_name = 'congestion')\n",
    "train_melt\n",
    "\n",
    "last_month = ss.time[0] - pd.Timedelta(days=60)\n",
    "lm = train_melt[train_melt.time >last_month].copy()\n",
    "lm['day_of_week'] = lm.time.dt.day % 7\n",
    "lm['hour'] = lm.time.dt.hour\n",
    "lm['minute'] = lm.time.dt.minute\n",
    "ss['day_of_week'] = ss.time.dt.day % 7\n",
    "ss['hour'] = ss.time.dt.hour\n",
    "ss['minute'] = ss.time.dt.minute\n",
    "\n",
    "#Getting quantiles\n",
    "lower = lm.groupby(['day_of_week','hour','minute', 'xydir']).congestion.quantile(0.15).reset_index()\n",
    "upper = lm.groupby(['day_of_week','hour','minute', 'xydir']).congestion.quantile(0.7).reset_index()\n",
    "\n",
    "#place quantiles in ss\n",
    "on = ['day_of_week','hour','minute', 'xydir']\n",
    "ss['lower'] = ss[on].merge(lower, on = on, how = 'left')['congestion']\n",
    "ss['upper'] = ss[on].merge(upper, on = on, how = 'left')['congestion']\n",
    "\n",
    "#Clip by quantiles\n",
    "ss['congestion'] = np.clip(ss['congestion'], ss['lower'], ss['upper'])\n",
    "\n",
    "#Submission\n",
    "ss['congestion'] = ss['congestion'] *100 #I scored 50+ when I forgot to do this.  Watch out!\n",
    "ss[['row_id','congestion']].to_csv('ss.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
