{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Task**\n",
        "#####It is a binary classification problem, where prediction would be either a person had Brain stroke(1) or not(0)\n",
        "**Dataset**\n",
        "#####Both train and test dataset was generated from a deep learning model trained on the Stroke Prediction Dataset.\n",
        "**Attributes**\n",
        "#####id: unique identifier\n",
        "#####gender: \"Male\", \"Female\" or \"Other\"\n",
        "#####age: age of the patient\n",
        "#####hypertension: 0 if the patient doesn't have hypertension, 1 if the patient has hypertension\n",
        "#####heart_disease: 0 if the patient doesn't have any heart diseases, 1 if the patient has a heart disease\n",
        "#####ever_married: \"No\" or \"Yes\"\n",
        "#####work_type: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" or \"Self-employed\"\n",
        "#####Residence_type: \"Rural\" or \"Urban\"\n",
        "#####avg_glucose_level: average glucose level in blood\n",
        "#####bmi: body mass index\n",
        "#####smoking_status: \"formerly smoked\", \"never smoked\", \"smokes\" or \"Unknown\"*\n",
        "#####stroke: 1 if the patient had a stroke or 0 if not"
      ],
      "metadata": {
        "id": "ZQDuCv4icluX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Library imports**"
      ],
      "metadata": {
        "id": "n7bZ2bzCcx8y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm4vBJybltWr"
      },
      "outputs": [],
      "source": [
        "import numpy as np             #provides support for multi-dimensional arrays and mathematical functions.\n",
        "import pandas as pd            #provides data manipulation and analysis tools.\n",
        "import matplotlib.pyplot as plt #plotting library for creating visualizations\n",
        "import seaborn as sns           #data visualization library based on matplotlib, providing additional tools for creating statistical graphics\n",
        "import missingno as msno        #visualization tool for exploring missing data in datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset"
      ],
      "metadata": {
        "id": "FQl_SzhKfFWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"train_data.csv\")\n",
        "df_test = pd.read_csv(\"test_data.csv\")\n",
        "original_data = pd.read_csv(\"stroke_data.csv\")"
      ],
      "metadata": {
        "id": "DXkIiuQve2m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for missing values\n",
        "df_train.isna().sum()"
      ],
      "metadata": {
        "id": "BtiFrvM2fHcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.isna().sum()"
      ],
      "metadata": {
        "id": "Rk4kEXM4e8Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data.isna().sum()"
      ],
      "metadata": {
        "id": "drMQlpGlfYW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(3)"
      ],
      "metadata": {
        "id": "vI0Y0TKFfZBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head(3)"
      ],
      "metadata": {
        "id": "hVLKS_14fcHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data.head(3)"
      ],
      "metadata": {
        "id": "RuRwxMnffe6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge train and original dataset**"
      ],
      "metadata": {
        "id": "P5ncWcLFfr9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping id column since we dont need it for data visualization\n",
        "original_data = (pd.concat([original_data,df_train],axis=0)).drop(columns=[\"id\"])"
      ],
      "metadata": {
        "id": "t-sidjfofkLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data.info()"
      ],
      "metadata": {
        "id": "shOJJ9cigBjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#handle null values\n",
        "original_data.isnull().sum()"
      ],
      "metadata": {
        "id": "HapQS8h6gFvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seperate categorical and numerical variables for visualization\n",
        "numerical_vars = original_data.select_dtypes(np.number).drop(columns=[\"stroke\"])\n",
        "categorical_vars = original_data.select_dtypes(\"object\")"
      ],
      "metadata": {
        "id": "9IXtfAMWgSCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_vars.head(3)"
      ],
      "metadata": {
        "id": "6npIwTFFm7vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_vars.tail(3)"
      ],
      "metadata": {
        "id": "UpNJ6cshm-ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#getting info about how many values that categorical variables have by using unique method\n",
        "#unique method is to extract unique values from the columns of categorical variables\n",
        "print(pd.unique(categorical_vars[\"gender\"]))\n",
        "print(pd.unique(categorical_vars[\"smoking_status\"]))\n",
        "print(pd.unique(categorical_vars[\"ever_married\"]))\n",
        "print(pd.unique(categorical_vars[\"work_type\"]))\n",
        "print(pd.unique(categorical_vars[\"Residence_type\"]))"
      ],
      "metadata": {
        "id": "MbC3ExyznC9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_vars.describe().T.style.background_gradient()"
      ],
      "metadata": {
        "id": "K3NOT_1ZnbLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####The numerical_vars dataframe is being described using the .describe() method, which generates a summary of statistics for each numerical column in the dataframe. The .T attribute is used to transpose the summary table, so that each column becomes a row.\n",
        "\n",
        "#####The .style.background_gradient() method is then used to apply a background color gradient to the resulting table. The color of each cell in the table will vary based on the value of the cell, with lower values being assigned a lighter color and higher values being assigned a darker color."
      ],
      "metadata": {
        "id": "RPuyP1Mrw0cK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA**"
      ],
      "metadata": {
        "id": "epoSHApnoNob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#histplot\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.subplot(1,3,1)\n",
        "sns.histplot(numerical_vars[\"age\"])\n",
        "plt.subplot(1,3,2)\n",
        "g1=sns.histplot(numerical_vars[\"avg_glucose_level\"],kde=True)\n",
        "g1.set(ylabel=None)\n",
        "plt.subplot(1,3,3)\n",
        "g1=sns.histplot(numerical_vars[\"bmi\"],kde=True)\n",
        "g1.set(ylabel=None)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "O-p1Hsjwnhg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### numerical_vars contains numerical variables such as age, average glucose level, and BMI, this code will produce a figure with three subplots. The first subplot will show a histogram of the \"age\" variable, while the second and third subplots will show histograms with KDE overlays of the \"avg_glucose_level\" and \"bmi\" variables, respectively. The g1.set(ylabel=None) command is again used to remove the y-label from the plot\n",
        "##### we can see that age is generally distributed between 20 and 60. Glucose levels seem normal but there are some high values.Bmi also same"
      ],
      "metadata": {
        "id": "93k35RN4xP60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#boxplot\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.subplot(1,3,1)\n",
        "sns.boxplot(numerical_vars[\"age\"]);\n",
        "plt.subplot(1,3,2)\n",
        "sns.boxplot(numerical_vars[\"avg_glucose_level\"]);\n",
        "plt.subplot(1,3,3)\n",
        "sns.boxplot(numerical_vars[\"bmi\"]);"
      ],
      "metadata": {
        "id": "fhRrZDxorOeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####This code will produce a figure with three subplots. Each subplot will show a boxplot of one of the numerical variables.\n",
        "#####Since avg_glucose_level seems normal, as we can see there are some values are higher. At Bmi, there are higher values like greater than 40, it means the people that who have greater than 40 value can carry high obesity risk"
      ],
      "metadata": {
        "id": "ReHK0wHHyuni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#countplot\n",
        "plt.figure(figsize=(17,6))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(\"Smoking Status by Gender\",fontsize=18)\n",
        "plt.ylabel(\"Count\",fontsize=18)\n",
        "plt.xlabel(\"Gender\",fontsize=18)\n",
        "sns.countplot(x=categorical_vars[\"gender\"],hue=\"smoking_status\",data=categorical_vars);\n",
        "plt.legend(loc=1, prop={'size': 11})\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title(\"Work Type by Gender\",fontsize=18)\n",
        "plt.xlabel(\"Gender\",fontsize=18)\n",
        "g1=sns.countplot(x=categorical_vars[\"gender\"],hue=\"work_type\",data=categorical_vars);\n",
        "g1.set(ylabel=None)\n",
        "plt.legend(loc=1, prop={'size': 11})\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(\"Residence Type\",fontsize=18)\n",
        "plt.xlabel(\"Gender\",fontsize=18)\n",
        "g1=sns.countplot(x=categorical_vars[\"gender\"],hue=\"Residence_type\",data=categorical_vars);\n",
        "plt.legend(loc=1, prop={'size': 11})\n",
        "g1.set(ylabel=None)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2aEzbLzsrUQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####The sns.countplot(x=categorical_vars[\"gender\"],hue=\"smoking_status\",data=categorical_vars) function call creates a countplot of the \"smoking_status\" variable by \"gender\" from the categorical_vars dataframe and plots it in this first subplot. The plt.title, plt.xlabel, plt.ylabel, and plt.legend function calls add various labels and a legend to the subplot.\n",
        "#####The sns.countplot(x=categorical_vars[\"gender\"],hue=\"work_type\",data=categorical_vars) function call creates a countplot of the \"work_type\" variable. The sns.countplot(x=categorical_vars[\"gender\"],hue=\"Residence_type\",data=categorical_vars) function call creates a countplot of the \"Residence_type\" variable by \"gender\""
      ],
      "metadata": {
        "id": "oaR8xGtHzDPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scatterplot\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.title(\"Age and Bmi Relationship\",fontsize=18)\n",
        "plt.xlabel(\"Age\",fontsize=18)\n",
        "plt.ylabel(\"Bmi\",fontsize=18)\n",
        "sns.scatterplot(x=\"age\",y=\"bmi\",data=original_data)\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title(\"Age and Average Glucose Level Relationship\",fontsize=18)\n",
        "plt.xlabel(\"Age\",fontsize=18)\n",
        "plt.ylabel(\"Average Glucose Level\",fontsize=18)\n",
        "sns.scatterplot(x=\"age\",y=\"avg_glucose_level\",data=original_data)\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title(\"Average Glucose Level and Bmi Relationship\",fontsize=18)\n",
        "plt.xlabel(\"Average Glucose Level\",fontsize=18)\n",
        "plt.ylabel(\"Bmi\",fontsize=18)\n",
        "sns.scatterplot(x=\"avg_glucose_level\",y=\"bmi\",data=original_data)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bxAsB1SFsAqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####There are three graphs now. For first graph, people who are between 20-60 have high bmi values for this data. According to the second graph, older age>40 people have high glucose level, that means, these people can have diabetics.For last graph, if your glucose value is low your bmi is low, too. That means, it can follow same way."
      ],
      "metadata": {
        "id": "HzOjweTv2iDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = original_data.corr()"
      ],
      "metadata": {
        "id": "ZcNb_zVmsYay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Created a correlation matrix of the numerical variables in the dataset. This will identify which variables are strongly correlated with each other, which can be useful in feature selection and modeling."
      ],
      "metadata": {
        "id": "cBOxuTE13RNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(font_scale=0.8)\n",
        "# plt.figure(figsize=(20,20))\n",
        "sns.heatmap(df_corr,annot=True,cmap=\"coolwarm\",square=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "doBoVToSsbYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####The heatmap shows the correlation matrix between the numerical variables. The color scale represents the correlation coefficient ranging from -1 to 1, where blue indicates negative correlation and red indicates positive correlation.\n",
        "\n",
        "#####Based on the heatmap, we can see that there are no strong correlations between the variables. However, we can observe a mild positive correlation between age and hypertension, as well as between age and heart disease. There is also a mild positive correlation between average glucose level and stroke, and between age and stroke."
      ],
      "metadata": {
        "id": "M2ODTidD37Ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelling**"
      ],
      "metadata": {
        "id": "vVFkxO10snaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separation of dependent and independent variables, preparing the dataset for algorithms or models and filling nulls with mean.\n",
        "original_data.isna().sum()"
      ],
      "metadata": {
        "id": "4OWeiAF5sppZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_data.fillna(original_data[\"bmi\"].mean(),inplace=True)"
      ],
      "metadata": {
        "id": "yqJXWfRcstOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = original_data.iloc[:,:-1]\n",
        "y = original_data.iloc[:,-1]\n",
        "X = pd.get_dummies(X,drop_first=True)"
      ],
      "metadata": {
        "id": "fl11PUwyswoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_percentage_error,roc_auc_score,roc_curve\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "lkjwEh1ns0Xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preproccessing the data: split the data into training and testing sets using the train_test_split function from sklearn. This will allow us to evaluate the performance of the logistic regression model on unseen data. This will split the data into 80% training and 20% testing sets, with a random state of 42 for reproducibility. "
      ],
      "metadata": {
        "id": "bc4XSz9V45ZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train , y_test = train_test_split(X,y,random_state=42)"
      ],
      "metadata": {
        "id": "PcI1XD9Xs4QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create ROC curve**"
      ],
      "metadata": {
        "id": "oVOD-XrWs81w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(solver=\"liblinear\").fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "pVwoL-UPs7D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####This code initializes a logistic regression model and trains it on the training data using the solver \"liblinear\". The solver parameter specifies the algorithm to use in the optimization problem, and \"liblinear\" is a solver that is commonly used for small to medium-sized datasets. The .fit() method fits the logistic regression model to the training data. The training data X_train contains the features, and y_train contains the target variable or labels."
      ],
      "metadata": {
        "id": "H5eASFa658US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "roc_auc=roc_auc_score(y,model.predict(X))\n",
        "fpr,tpr,thresholds = roc_curve(y,model.predict_proba(X)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr,tpr,label=\"AUC (area=%0.2f)\"%roc_auc)\n",
        "plt.plot([0,1],[0,1],\"r--\")\n",
        "plt.xlim([0.0,1.0])\n",
        "plt.ylim([0.0,1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gj19p73ctC4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####This code calculates the Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) score for a logistic regression model. It plots the ROC curve with FPR on the x-axis and TPR on the y-axis. plt.plot([0, 1], [0, 1], \"r--\") adds a dashed diagonal line representing a random classifier. plt.xlim([0.0, 1.0]) sets the limits of the x-axis to [0, 1]. plt.ylim([0.0, 1.05]) sets the limits of the y-axis to [0, 1.05].\n"
      ],
      "metadata": {
        "id": "iBKDxjMf6jrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "LSD2ORJTtI8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get a score of 0.957. A model score of 0.957 indicates that the logistic regression model is able to predict the stroke occurrence in the given dataset with 95.7% accuracy. This means that the model is able to correctly identify the occurrence or non-occurrence of stroke in 95.7% of the cases based on the selected features."
      ],
      "metadata": {
        "id": "9yQwynvL7GRU"
      }
    }
  ]
}