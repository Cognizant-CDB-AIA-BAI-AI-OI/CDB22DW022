{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this competition, you will predict the popularity of a set of New York Times blog articles from the time period September 2014-December 2014.\n",
    " \n",
    " Many blog articles are published each day, and the New York Times has to decide which articles should be featured. In this competition, we challenge you to develop an analytics model that will help the New York Times understand the features of a blog post that make it popular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "KeQeZXTX9DKI"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QHW0atOI9DKN"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "File Descriptions\n",
    "The data provided for this competition is split into two files:\n",
    "\n",
    "NYTimesBlogTrain.csv = the training data set. It consists of 6532 articles.\n",
    "NYTimesBlogTest.csv = the testing data set. It consists of 1870 articles.  \n",
    "We have also provided a sample submission file, SampleSubmission.csv. This file gives an example of the format of submission files (see the Evaluation page for more information). The data for this competition comes from the New York Times website.\n",
    "\n",
    "# Variable Descriptions\n",
    "The dependent variable in this problem is the variable Popular, which labels if an article had 25 or more comments in its online comment section (equal to 1 if it did, and 0 if it did not). The dependent variable is provided in the training data set, but not the testing dataset. This is an important difference from what you are used to - you will not be able to see how well your model does on the test set until you make a submission on Kaggle.\n",
    "\n",
    "The independent variables consist of 8 pieces of article data available at the time of publication, and a unique identifier:\n",
    "\n",
    "NewsDesk = the New York Times desk that produced the story (Business, Culture, Foreign, etc.)\n",
    "SectionName = the section the article appeared in (Opinion, Arts, Technology, etc.)\n",
    "SubsectionName = the subsection the article appeared in (Education, Small Business, Room for Debate, etc.)\n",
    "Headline = the title of the article\n",
    "Snippet = a small portion of the article text\n",
    "Abstract = a summary of the blog article, written by the New York Times\n",
    "WordCount = the number of words in the article\n",
    "PubDate = the publication date, in the format \"Year-Month-Day Hour:Minute:Second\"\n",
    "UniqueID = a unique identifier for each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "HmlrWDG09POS",
    "outputId": "2f95ed27-8840-4bfb-83de-bbf83b709177"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-bb3206f0-6f38-4f21-b264-ef35ef76d98c\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-bb3206f0-6f38-4f21-b264-ef35ef76d98c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving NY_train.csv to NY_train.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "ZIZfdE-T9uwW",
    "outputId": "3eac2b43-4deb-4e15-8979-fe0717bdc846"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7cea2ef8-8068-4b38-a07f-ba8b1fc5dd82\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-7cea2ef8-8068-4b38-a07f-ba8b1fc5dd82\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving NY_test.csv to NY_test.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded=files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DwmXZaJ69DKO"
   },
   "outputs": [],
   "source": [
    "NYT_train_raw = pd.read_csv(\"NY_train.csv\")\n",
    "NYT_test_raw = pd.read_csv(\"NY_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BaTiaBt9DKO"
   },
   "source": [
    "Join the data for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0n_in3vg9DKQ",
    "outputId": "601365a4-40a0-4888-b2dd-55dc877cecfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max train ID: 6532. Max test ID: 8402\n"
     ]
    }
   ],
   "source": [
    "print('Max train ID: %d. Max test ID: %d' % (np.max(NYT_train_raw['UniqueID']), np.max(NYT_test_raw['UniqueID'])))\n",
    "joined = NYT_train_raw.merge(NYT_test_raw, how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlzI_XwG9DKS"
   },
   "source": [
    "Create additional features:\n",
    "\n",
    "\"QorE\": question or exclamation mark in the headline\n",
    "\"Q&A\": \"Q. and A.\" phrase in the headline (I don't think it was valuable, but stayed here from my previous attemps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c4o9l20O9DKX"
   },
   "outputs": [],
   "source": [
    "joined['QorE'] = joined['Headline'].str.contains(r'\\!|\\?').astype(int)\n",
    "joined['Q&A'] = joined['Headline'].str.contains(r'Q\\. and A\\.').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnF0o5BP9DKY"
   },
   "source": [
    "Convert \"PubDate\" into two columns: Weekday and Hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NWnEUqCb9DKZ"
   },
   "outputs": [],
   "source": [
    "joined['PubDate'] = pd.to_datetime(joined['PubDate'])\n",
    "joined['Weekday'] = joined['PubDate'].dt.weekday\n",
    "joined['Hour'] = joined['PubDate'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlXGBS_b9DKa",
    "outputId": "bce208ea-d267-44bc-81fe-ed2d21c09bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the moment, we have 2408 entries with NewsDesk=Nan.\n"
     ]
    }
   ],
   "source": [
    "print(\"At the moment, we have %d entries with NewsDesk=Nan.\" % len(joined.loc[joined['NewsDesk'].isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2SDMocy9DKb"
   },
   "source": [
    "# More features and gap filling\n",
    "\n",
    "Below are the results of one day of searching for meaningful patterns in the data. There are a few easily identifiable features, most of which lead to zero popularity. They are:\n",
    "\n",
    "\"History\": article headings always started with a year. None of them were popular in the training set\n",
    "\"Daily rubric\": I added this new NewsDesk category for types of articles that appeared regularly (not necessarily daily): \"Daily Clip Report\", \"Today in Politics\", \"What we're reading\", \"First Draft\", \"Pictures of the day\", \"Week in pictures\". They also were not popular.\n",
    "Now, as ask788 pointed out in this thread, the problem with data is often their structure, not the models we use on them. I agree that ideally this feature engineering should have been done automatically, but I am a novice, and had to tediously plod through the rows of data manually.\n",
    "\n",
    "You can browse individual features that I selected by printing the head() of a subset, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "GYUWj9d09DKc",
    "outputId": "423e78bd-e06d-4cea-a351-7f08b95c3d39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-67e7cab6-49c3-45d1-ba0e-656be0a0ad1c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>Popular</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>QorE</th>\n",
       "      <th>Q&amp;A</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1939: German Troops Invade Poland</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>97</td>\n",
       "      <td>2014-09-01 14:39:43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1914: Russian Army Scores Victory</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>108</td>\n",
       "      <td>2014-09-01 09:30:14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1914: City Prepares for War Wounded</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>101</td>\n",
       "      <td>2014-09-02 13:34:59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1889: British Traders in East Africa</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>122</td>\n",
       "      <td>2014-09-02 10:48:08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1939: War on Germany Declared</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>Highlights from the International Herald Tribu...</td>\n",
       "      <td>79</td>\n",
       "      <td>2014-09-03 07:41:26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67e7cab6-49c3-45d1-ba0e-656be0a0ad1c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-67e7cab6-49c3-45d1-ba0e-656be0a0ad1c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-67e7cab6-49c3-45d1-ba0e-656be0a0ad1c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    NewsDesk SectionName SubsectionName                              Headline  \\\n",
       "11   Foreign         NaN            NaN    1939: German Troops Invade Poland    \n",
       "20   Foreign         NaN            NaN     1914: Russian Army Scores Victory   \n",
       "67   Foreign         NaN            NaN   1914: City Prepares for War Wounded   \n",
       "81   Foreign         NaN            NaN  1889: British Traders in East Africa   \n",
       "184  Foreign         NaN            NaN         1939: War on Germany Declared   \n",
       "\n",
       "                                               Snippet  \\\n",
       "11   Highlights from the International Herald Tribu...   \n",
       "20   Highlights from the International Herald Tribu...   \n",
       "67   Highlights from the International Herald Tribu...   \n",
       "81   Highlights from the International Herald Tribu...   \n",
       "184  Highlights from the International Herald Tribu...   \n",
       "\n",
       "                                              Abstract  WordCount  \\\n",
       "11   Highlights from the International Herald Tribu...         97   \n",
       "20   Highlights from the International Herald Tribu...        108   \n",
       "67   Highlights from the International Herald Tribu...        101   \n",
       "81   Highlights from the International Herald Tribu...        122   \n",
       "184  Highlights from the International Herald Tribu...         79   \n",
       "\n",
       "                PubDate  Popular  UniqueID  QorE  Q&A  Weekday  Hour  \n",
       "11  2014-09-01 14:39:43      0.0        12     0    0        0    14  \n",
       "20  2014-09-01 09:30:14      0.0        21     0    0        0     9  \n",
       "67  2014-09-02 13:34:59      0.0        68     0    0        1    13  \n",
       "81  2014-09-02 10:48:08      0.0        82     0    0        1    10  \n",
       "184 2014-09-03 07:41:26      0.0       185     0    0        2     7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.loc[(joined['NewsDesk'] == 'Foreign') & (joined['SectionName'].isnull())].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oDjgBpoY9DKd"
   },
   "outputs": [],
   "source": [
    "joined.loc[(joined['NewsDesk'] == 'Styles') & (joined['SectionName'].isnull()), 'NewsDesk'] = 'TStyle'\n",
    "joined.loc[(joined['NewsDesk'] == 'Foreign') & (joined['SectionName'].isnull()), 'NewsDesk'] = 'History'\n",
    "joined.loc[(joined['NewsDesk'].isnull()) & (joined['Headline'].str.contains(r'^1[0-9]{3}')), 'NewsDesk'] = 'History'\n",
    "joined.loc[(joined['NewsDesk'].isnull()) & (joined['Headline'] == 'Daily Clip Report'), 'NewsDesk'] = 'Daily Rubric'\n",
    "joined.loc[joined['NewsDesk'] == 'Daily Rubric', 'SectionName'] = 'Clip Report'\n",
    "joined.loc[(joined['NewsDesk'].isnull()) & (joined['Headline'] == 'Today in Politics'), 'SectionName'] = 'Today in Politics'\n",
    "joined.loc[joined['SectionName'] == 'Today in Politics', 'NewsDesk'] = 'Daily Rubric'\n",
    "joined.loc[(joined['NewsDesk'].isnull()) & (joined['Headline'].str.contains(r'what we\\'re reading', case=False)), 'SectionName'] = 'What we\\'re reading'\n",
    "joined.loc[joined['SectionName'] == 'What we\\'re reading', 'NewsDesk'] = 'Daily Rubric'\n",
    "joined.loc[(joined['NewsDesk'].isnull()) & (joined['Headline'].str.contains(r'first draft', case=False)), 'SectionName'] = 'First draft'\n",
    "joined.loc[joined['SectionName'] == 'First draft', 'NewsDesk'] = 'Daily Rubric'\n",
    "joined.loc[(joined['NewsDesk'].isnull()) & (joined['SubsectionName'] == 'Education'), 'NewsDesk'] = 'Daily Rubric'\n",
    "joined.loc[(joined['Headline'].str.contains('pictures of the day|week in pictures', case=False)), 'NewsDesk'] = 'Daily Rubric'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4sCNCuH9DKe"
   },
   "source": [
    "Filling the gaps in NewsDesk, SectionName and SubsectionName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BzGmXJVn9DKe"
   },
   "outputs": [],
   "source": [
    "section_to_newsdesk = {'Business Day': 'Business', 'Crosswords/Games': 'Business', 'Technology': 'Business',\n",
    "     'Arts': 'Culture',\n",
    "     'World': 'Foreign',\n",
    "     'Magazine': 'Magazine',\n",
    "     'N.Y. / Region': 'Metro',\n",
    "     'Opinion': 'OpEd',\n",
    "     'Travel': 'Travel',\n",
    "     'Multimedia': 'Multimedia',\n",
    "     'Open': 'Open'}\n",
    "\n",
    "section_to_subsection = {'Crosswords/Games': 'Crosswords/Games',\n",
    "                        'Technology': 'Technology'}\n",
    "\n",
    "newsdesk_to_section = {'TStyle': 'TStyle',\n",
    "                      'Culture': 'Arts',\n",
    "                      'OpEd': 'Opinion',\n",
    "                      'History': 'History'}\n",
    "\n",
    "newsdesk_to_subsection = {'TStyle': 'TStyle',\n",
    "                         'Culture': 'Arts',\n",
    "                         'Daily Rubric': 'Rubric',\n",
    "                         'Magazine': 'Magazine',\n",
    "                         'Metro': 'Metro',\n",
    "                         'Multimedia': 'Multimedia',\n",
    "                         'OpEd': 'OpEd',\n",
    "                         'Science': 'Science',\n",
    "                         'Sports': 'Sports',\n",
    "                         'Styles': 'Styles',\n",
    "                         'Travel': 'Travel',\n",
    "                         'History': 'History'}\n",
    "for sec in set(joined['SectionName']):\n",
    "    try: section_to_newsdesk[sec]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    else:\n",
    "        joined['NewsDesk'].fillna(joined.loc[(joined['SectionName'] == sec)]['NewsDesk'].fillna(section_to_newsdesk[sec]), inplace=True)\n",
    "\n",
    "    try: section_to_subsection[sec]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    else:\n",
    "        joined['SubsectionName'].fillna(joined.loc[(joined['SectionName'] == sec)]['SubsectionName'].fillna(section_to_subsection[sec]), inplace=True)        \n",
    "\n",
    "\n",
    "for nd in set(joined['NewsDesk']):\n",
    "    try: newsdesk_to_section[nd]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    else:\n",
    "        joined['SectionName'].fillna(joined.loc[(joined['NewsDesk'] == nd)]['SectionName'].fillna(newsdesk_to_section[nd]), inplace=True)\n",
    "        \n",
    "    try: newsdesk_to_subsection[nd]\n",
    "    except KeyError:\n",
    "        pass\n",
    "    else:\n",
    "        joined['SubsectionName'].fillna(joined.loc[(joined['NewsDesk'] == nd)]['SubsectionName'].fillna(newsdesk_to_subsection[nd]), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1h7IX5k59DKf"
   },
   "source": [
    "Filling even more gaps with some clustering. I created a TFI-DF matrix and did Ward clustering on words. Four of six clusters I thought were meaningful and fitted well into existing NewsDesk/S(ubs)ectionName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgJG9bEB9DKg",
    "outputId": "f1d9c2b2-ded4-446e-9e7e-c4401a8a1d7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/utils/_param_validation.py:558: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nans = joined.loc[joined['NewsDesk'].isnull()]\n",
    "words = list(nans.apply(lambda x:'%s' % (x['Abstract']),axis=1))\n",
    "tfv = TfidfVectorizer(min_df=0.005,  max_features=None, \n",
    "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 2), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "        stop_words = 'english')\n",
    "X_tr = tfv.fit_transform(words)\n",
    "\n",
    "ward = AgglomerativeClustering(n_clusters=6,\n",
    "        linkage='ward').fit(X_tr.toarray())\n",
    "\n",
    "joined.loc[joined['NewsDesk'].isnull(), 'cluster'] = ward.labels_\n",
    "cluster_to = {}\n",
    "cluster_to['NewsDesk'] = {4: 'Metro', 3: 'National', 2: 'Foreign', 1: 'National'}\n",
    "cluster_to['SectionName'] = {4: 'N.Y. / Region', 3: 'U.S.', 2: 'Not_Asia', 1: 'U.S.'}\n",
    "cluster_to['SubsectionName'] = {4: 'NYT', 3: 'Politics', 2: 'Not_Asia', 1: 'Politics'}\n",
    "\n",
    "for key in cluster_to:\n",
    "    for key2 in cluster_to[key]:\n",
    "        joined.loc[(joined['cluster'] == key2) & (nans['NewsDesk'].isnull()), key] = cluster_to[key][key2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8yQoIVq9DKh"
   },
   "source": [
    "You can see what these clusters look like by typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "xSt1bWfh9DKi",
    "outputId": "b2c390d8-cae7-4e0a-afc5-86d08c62026a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-39f4484b-57d8-4499-bd98-230e6e25d8f7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDesk</th>\n",
       "      <th>SectionName</th>\n",
       "      <th>SubsectionName</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>PubDate</th>\n",
       "      <th>Popular</th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>QorE</th>\n",
       "      <th>Q&amp;A</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Hour</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>National</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Congress to Weigh In on White House Security</td>\n",
       "      <td>The House Committee on Oversight and Governmen...</td>\n",
       "      <td>The House Committee on Oversight and Governmen...</td>\n",
       "      <td>98</td>\n",
       "      <td>2014-09-22 16:50:03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1511</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>National</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>White House Will Use Locks More Often</td>\n",
       "      <td>White House Not Changing the Locks Just Yet</td>\n",
       "      <td>White House Not Changing the Locks Just Yet</td>\n",
       "      <td>304</td>\n",
       "      <td>2014-09-22 12:49:19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>National</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>The White House Front Door, When Entered Properly</td>\n",
       "      <td>A brief history of the White Houses North Port...</td>\n",
       "      <td>A brief history of the White Houses North Port...</td>\n",
       "      <td>220</td>\n",
       "      <td>2014-09-22 10:18:46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1570</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>National</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Lunchtime Laughs: Jumper at 1600</td>\n",
       "      <td>The Daily Shows take on the disturbing details...</td>\n",
       "      <td>The Daily Shows take on the disturbing details...</td>\n",
       "      <td>114</td>\n",
       "      <td>2014-09-23 12:40:54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1673</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>National</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>Politics</td>\n",
       "      <td>White House Reporters Working on Pool End-Around</td>\n",
       "      <td>The White House Correspondents Association is ...</td>\n",
       "      <td>The White House Correspondents Association is ...</td>\n",
       "      <td>210</td>\n",
       "      <td>2014-09-24 14:46:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1777</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39f4484b-57d8-4499-bd98-230e6e25d8f7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-39f4484b-57d8-4499-bd98-230e6e25d8f7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-39f4484b-57d8-4499-bd98-230e6e25d8f7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      NewsDesk SectionName SubsectionName  \\\n",
       "1510  National        U.S.       Politics   \n",
       "1540  National        U.S.       Politics   \n",
       "1569  National        U.S.       Politics   \n",
       "1672  National        U.S.       Politics   \n",
       "1776  National        U.S.       Politics   \n",
       "\n",
       "                                               Headline  \\\n",
       "1510       Congress to Weigh In on White House Security   \n",
       "1540             White House Will Use Locks More Often    \n",
       "1569  The White House Front Door, When Entered Properly   \n",
       "1672                   Lunchtime Laughs: Jumper at 1600   \n",
       "1776   White House Reporters Working on Pool End-Around   \n",
       "\n",
       "                                                Snippet  \\\n",
       "1510  The House Committee on Oversight and Governmen...   \n",
       "1540        White House Not Changing the Locks Just Yet   \n",
       "1569  A brief history of the White Houses North Port...   \n",
       "1672  The Daily Shows take on the disturbing details...   \n",
       "1776  The White House Correspondents Association is ...   \n",
       "\n",
       "                                               Abstract  WordCount  \\\n",
       "1510  The House Committee on Oversight and Governmen...         98   \n",
       "1540        White House Not Changing the Locks Just Yet        304   \n",
       "1569  A brief history of the White Houses North Port...        220   \n",
       "1672  The Daily Shows take on the disturbing details...        114   \n",
       "1776  The White House Correspondents Association is ...        210   \n",
       "\n",
       "                 PubDate  Popular  UniqueID  QorE  Q&A  Weekday  Hour  cluster  \n",
       "1510 2014-09-22 16:50:03      0.0      1511     0    0        0    16      3.0  \n",
       "1540 2014-09-22 12:49:19      0.0      1541     0    0        0    12      3.0  \n",
       "1569 2014-09-22 10:18:46      0.0      1570     0    0        0    10      3.0  \n",
       "1672 2014-09-23 12:40:54      0.0      1673     0    0        1    12      3.0  \n",
       "1776 2014-09-24 14:46:28      0.0      1777     0    0        2    14      3.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.loc[joined['cluster'] == 3].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35EVuknF9DKj"
   },
   "source": [
    "Finally, use a few (6) obvious keywords to categorise the data even more. After this, we are left with 950 entries where NewsDesk, SectionName and SubsectionName are NaN, but I didn't have an idea how to deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-tcI1Xsl9DKl"
   },
   "outputs": [],
   "source": [
    "joined.drop('cluster', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "P2kw3fKf9DKl"
   },
   "outputs": [],
   "source": [
    "keywords = {}\n",
    "keywords['clinton|white house|obama'] = {'NewsDesk': 'National', 'SectionName': 'U.S.', 'SubsectionName': 'Politics'}\n",
    "keywords['isis|iraq'] = {'NewsDesk': 'Foreign', 'SectionName': 'Not_Asia', 'SubsectionName': 'Not_Asia'}\n",
    "keywords['york'] = {'NewsDesk': 'Metro', 'SectionName': 'N.Y. / Region', 'SubsectionName': 'N.Y. / Region'}\n",
    "\n",
    "for key in keywords:\n",
    "    indices = (joined['NewsDesk'].isnull()) & (joined['Abstract'].str.contains(key, case=False))\n",
    "    for sec in keywords[key]:\n",
    "        joined.loc[indices, sec] = keywords[key][sec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEBtT1GV9DKm",
    "outputId": "c9631348-3bcd-42f1-9476-a48a8b4161fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 948 entries with NewsDesk=Nan.\n"
     ]
    }
   ],
   "source": [
    "print(\"Now we have %d entries with NewsDesk=Nan.\" % len(joined.loc[joined['NewsDesk'].isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoI0q2sz9DKn"
   },
   "source": [
    "# Categorical (factor) colums\n",
    "\n",
    "First, turn the categorial data into 0/1 binary columns. Yes, it's more painful in Python than in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2pSxRfz89DKn"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "def categorizeDF(df):\n",
    "    old_columns = df.columns\n",
    "    cat_cols = ['NewsDesk', 'SectionName', 'SubsectionName']\n",
    "    temp_dict = df[cat_cols].to_dict(orient=\"records\")\n",
    "    vec = DictVectorizer()\n",
    "    vec_arr = vec.fit_transform(temp_dict).toarray()\n",
    "    \n",
    "    new_df = pd.DataFrame(vec_arr).convert_dtypes(convert_integer=True)\n",
    "    new_df.index = df.index\n",
    "    new_df.columns = vec.get_feature_names_out()\n",
    "    columns_to_add = [col for col in old_columns if col not in cat_cols]\n",
    "    new_df[columns_to_add] = df[columns_to_add]\n",
    "    new_df.drop(cat_cols, inplace=True, axis=1)\n",
    "    return new_df\n",
    "\n",
    "joined_cat = categorizeDF(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPUpb-nO9DKo"
   },
   "source": [
    "# Recover train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SVtlLiyV9DKp"
   },
   "outputs": [],
   "source": [
    "train = joined_cat[joined_cat['UniqueID'] <= 6532]\n",
    "test = joined_cat[joined_cat['UniqueID'] > 6532]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohxOr2mM9DKp"
   },
   "source": [
    "# Random Forest\n",
    "\n",
    "Parametres for RF had been optimised with a GridSearchCV function from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rajUFy0y9DKp",
    "outputId": "20541129-b07f-4b2b-de60-9d69156d6850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Fold CV Score:  0.9462052194546713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Xcols = train.columns\n",
    "Xcols = [x for x in Xcols if not x in ('Headline', 'Snippet', 'Abstract', 'PubDate', 'UniqueID', 'Popular', 'Q&A')]\n",
    "\n",
    "y = train['Popular']\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=7000, max_features=0.1, min_samples_split=24, random_state=33, n_jobs=3)\n",
    "forest.fit(train[Xcols], y)\n",
    "\n",
    "probsRF = forest.predict_proba(test[Xcols])[:,1]\n",
    "\n",
    "print(\"10 Fold CV Score: \", np.mean(cross_val_score(forest, train[Xcols], y, cv=10, scoring='roc_auc')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrhmzH1z9DKq"
   },
   "source": [
    "# Gradient Boosting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRTpz8O-9DKq",
    "outputId": "feb019e6-7e07-4667-9faf-063f1ee3c869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Fold CV Score:  0.9455640054930132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "Xcols = train.columns\n",
    "Xcols = [x for x in Xcols if not x in ('Headline', 'Snippet', 'Abstract', 'PubDate', 'UniqueID', 'Popular', 'Q&A')]\n",
    "\n",
    "y = train['Popular']\n",
    "\n",
    "est = GradientBoostingClassifier(n_estimators=3000,\n",
    "                                 learning_rate=0.005,\n",
    "                                 max_depth=4,\n",
    "                                 max_features=0.3,\n",
    "                                 min_samples_leaf=9,\n",
    "                                 random_state=33)\n",
    "est.fit(train[Xcols], y)\n",
    "\n",
    "probsGBC = est.predict_proba(test[Xcols])[:,1]\n",
    "\n",
    "print(\"10 Fold CV Score: \", np.mean(cross_val_score(est, train[Xcols], y, cv=10, scoring='roc_auc')))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
