{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930e1738",
   "metadata": {},
   "source": [
    "### Santander Customer Transaction Prediction \n",
    "     \n",
    "     \n",
    "### - Prepared By Soumee Ghosh(2211444)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3101481",
   "metadata": {},
   "source": [
    "### Problem Description\n",
    "At Santander our mission is to help people and businesses prosper. We are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals.\n",
    "\n",
    "Our data science team is continually challenging our machine learning algorithms, working with the global data science community to make sure we can more accurately identify new ways to solve our most common challenge, binary classification problems such as: is a customer satisfied? Will a customer buy this product? Can a customer pay this loan?\n",
    "\n",
    "In this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce672c",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "You are provided with an anonymized dataset containing numeric feature variables, the binary target column, and a string ID_code column.\n",
    "\n",
    "The task is to predict the value of target column in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531129e8",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries\n",
    "\n",
    "1. Data Wrangling libraries: \n",
    " * `numpy` : Numpy is a general-purpose array-processing package. It provides a high-performance multidimensional array object, and tools for working with these arrays\n",
    " * `pandas`: Pandas is an open-source library that is built on top of NumPy library. It is a Python package that offers various data structures and operations for manipulating numerical data and time series. It is mainly popular for importing and analyzing data much easier. Pandas is fast and it has high-performance & productivity for users.\n",
    " \n",
    "2. data visualization library: \n",
    " * `matplotlib`:Matplotlib is a low level graph plotting library in python that serves as a visualization utility.\n",
    " * `seaborn`: Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. \n",
    " \n",
    " \n",
    "3. data  Pre-processing Libraries: \n",
    " Using the sciit learn package `MinMaxScaler` and `StandardScaler` are imported which will be used for sclaing the data. The `train_test_split` is used for dividing te data into training, validation and test set for model building . In case of imbalanced dataset `stratifiedKFold` can be used. \n",
    " * `Stratified K fold` : It provides train/test indices to split data in train/test sets.This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.\n",
    " \n",
    " * `RandomizedsearchCv`: Randomized search on hyper parameters.RandomizedSearchCV implements a “fit” and a “score” method. It also implements “score_samples”, “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.The parameters of the estimator used to apply these methods are optimized by cross-validated search over parameter settings.\n",
    "\n",
    "In contrast to `GridSearchCV`, not all parameter values are tried out, but rather a fixed number of parameter settings is sampled from the specified distributions. The number of parameter settings that are tried is given by n_iter.\n",
    "If all parameters are presented as a list, sampling without replacement is performed. If at least one parameter is given as a distribution, sampling with replacement is used. It is highly recommended to use continuous distributions for continuous parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "607f308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Wrangling Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#data Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "#Data Preprocessing Libraries\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Machine Learning Libraries\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import auc, roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29dc0ef",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "\n",
    "using `read_csv` we try to read the data into a pandas dataframe.\n",
    "\n",
    "`.head()` gives the first 5 observations in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2483fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24529434",
   "metadata": {},
   "source": [
    "### Checking the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa1ef70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 202)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a23ad7d",
   "metadata": {},
   "source": [
    "#### There are 200000 rows and 202 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738af40c",
   "metadata": {},
   "source": [
    "### Checking the info of the dataset using `.info()` method\n",
    "\n",
    "The `info()` method prints information about the DataFrame.The information contains the number of columns, column labels, column data types, memory usage, range index, and the number of cells in each column (non-null values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481580c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe291e0",
   "metadata": {},
   "source": [
    "### Checking the statistical description using `.describe()` method.\n",
    "\n",
    "The `.describe()` method returns description of the data in the DataFrame.\n",
    "\n",
    "If the DataFrame contains numerical data, the description contains these information for each column:\n",
    "\n",
    "count - The number of not-empty values.\n",
    "mean - The average (mean) value.\n",
    "std - The standard deviation.\n",
    "min - the minimum value.\n",
    "25% - The 25% percentile*.\n",
    "50% - The 50% percentile*.\n",
    "75% - The 75% percentile*.\n",
    "max - the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289d60de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f24253",
   "metadata": {},
   "source": [
    "### Checking for presence of null values\n",
    "\n",
    "`.isnull()` is used for checking the presence of null values and `.sort_values` is used for sorting the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5464a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_code    0\n",
       "var_126    0\n",
       "var_127    0\n",
       "var_128    0\n",
       "var_129    0\n",
       "          ..\n",
       "var_69     0\n",
       "var_70     0\n",
       "var_71     0\n",
       "var_61     0\n",
       "var_199    0\n",
       "Length: 202, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89fee4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_code    0\n",
       "var_126    0\n",
       "var_127    0\n",
       "var_128    0\n",
       "var_129    0\n",
       "          ..\n",
       "var_69     0\n",
       "var_70     0\n",
       "var_71     0\n",
       "var_61     0\n",
       "var_199    0\n",
       "Length: 201, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a820f",
   "metadata": {},
   "source": [
    "### So we observe that there are no null values present in the training as well as testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f99eaa7",
   "metadata": {},
   "source": [
    "#### Using `.drop_duplicates` we drop if there is presence of any duplicate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11a2dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be6e54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d97529ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "\n",
       "[3 rows x 202 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b47ba8",
   "metadata": {},
   "source": [
    "#### `.drop()` is used for dropping the ID_code column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "490bf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"ID_code\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7349cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.093</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.389</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target    var_0   var_1    var_2  var_3    var_4   var_5   var_6    var_7  \\\n",
       "0       0   8.9255 -6.7863  11.9081  5.093  11.4607 -9.2834  5.1187  18.6266   \n",
       "1       0  11.5006 -4.1473  13.8588  5.389  12.3622  7.0433  5.6208  16.5338   \n",
       "\n",
       "    var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0 -4.9200  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  3.1468  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "\n",
       "[2 rows x 201 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f29b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7  \\\n",
       "0  test_0  11.0656  7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493  18.2675   \n",
       "1  test_1   8.5304  1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196  18.6316   \n",
       "\n",
       "    var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   4.3654   \n",
       "1 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773  -1.4852   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0  10.7200  15.4722  -8.7197  \n",
       "1   9.8714  19.1293 -20.9760  \n",
       "\n",
       "[2 rows x 201 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "162b06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(\"ID_code\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a7d2b6",
   "metadata": {},
   "source": [
    "#### Now using `.value_counts()`we check the distribution of the target column of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b91f7611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c867803b",
   "metadata": {},
   "source": [
    "#### Here we plot the distribution of the target column using a `pie chart` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fd16903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2230118a550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.target.value_counts().plot(kind=\"pie\",labels=[\"0\",\"1\"],autopct=\"%.2f%%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00ef9f",
   "metadata": {},
   "source": [
    "* The target column is imbalanced, \n",
    "* So we need to balance it either using undersampling or oversampling or use stratified k fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff8bc01",
   "metadata": {},
   "source": [
    "### Using `.skew()`  method we check the skewness of all the columns of the taining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9b3361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target     2.657642\n",
       "var_0      0.235639\n",
       "var_1      0.053115\n",
       "var_2      0.260313\n",
       "var_3     -0.003548\n",
       "             ...   \n",
       "var_195    0.124048\n",
       "var_196   -0.032527\n",
       "var_197   -0.031094\n",
       "var_198   -0.170156\n",
       "var_199   -0.164349\n",
       "Length: 201, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28eab8",
   "metadata": {},
   "source": [
    "### Here we are using `undersampling`.\n",
    "\n",
    "`Undersampling` is a common technique used to address the issue of imbalanced classes in machine learning. When dealing with imbalanced datasets, where one class has significantly fewer instances than the other(s), the model tends to be biased towards the majority class, leading to poor performance on the minority class. Undersampling aims to alleviate this problem by reducing thenumber of instances in the majority class to balance the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c10317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "target_0 = train[train.target == 0]\n",
    "target_1 = train[train.target == 1]\n",
    "\n",
    "target_0_downsampled = resample(target_0, replace = False, n_samples = len(target_1), random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f8e2d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20098, 201)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_0_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f2e9d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20098, 201)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2472370f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20098\n",
       "0    20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled = pd.concat([target_0_downsampled, target_1])\n",
    "downsampled.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8ccb5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137312</th>\n",
       "      <td>0</td>\n",
       "      <td>12.8349</td>\n",
       "      <td>-1.8347</td>\n",
       "      <td>9.7758</td>\n",
       "      <td>6.3049</td>\n",
       "      <td>12.2757</td>\n",
       "      <td>-9.9022</td>\n",
       "      <td>6.8161</td>\n",
       "      <td>15.2060</td>\n",
       "      <td>3.3815</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1672</td>\n",
       "      <td>6.2511</td>\n",
       "      <td>4.2107</td>\n",
       "      <td>12.0961</td>\n",
       "      <td>20.7002</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>-5.4146</td>\n",
       "      <td>9.8854</td>\n",
       "      <td>10.4776</td>\n",
       "      <td>-12.2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16192</th>\n",
       "      <td>0</td>\n",
       "      <td>12.7580</td>\n",
       "      <td>2.5818</td>\n",
       "      <td>9.6942</td>\n",
       "      <td>5.0552</td>\n",
       "      <td>9.7792</td>\n",
       "      <td>-0.0449</td>\n",
       "      <td>7.4387</td>\n",
       "      <td>22.7764</td>\n",
       "      <td>1.5262</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2251</td>\n",
       "      <td>10.1442</td>\n",
       "      <td>1.3667</td>\n",
       "      <td>6.5912</td>\n",
       "      <td>19.6133</td>\n",
       "      <td>-0.4250</td>\n",
       "      <td>1.9741</td>\n",
       "      <td>9.9844</td>\n",
       "      <td>19.0760</td>\n",
       "      <td>13.4439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22656</th>\n",
       "      <td>0</td>\n",
       "      <td>7.1304</td>\n",
       "      <td>-8.7134</td>\n",
       "      <td>11.5949</td>\n",
       "      <td>8.7937</td>\n",
       "      <td>12.5311</td>\n",
       "      <td>-3.4522</td>\n",
       "      <td>6.1531</td>\n",
       "      <td>17.0418</td>\n",
       "      <td>1.8732</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.9856</td>\n",
       "      <td>9.8221</td>\n",
       "      <td>1.8566</td>\n",
       "      <td>3.6718</td>\n",
       "      <td>15.3979</td>\n",
       "      <td>-0.2740</td>\n",
       "      <td>4.8341</td>\n",
       "      <td>9.0588</td>\n",
       "      <td>16.6492</td>\n",
       "      <td>-8.0587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63767</th>\n",
       "      <td>0</td>\n",
       "      <td>14.6030</td>\n",
       "      <td>-0.1394</td>\n",
       "      <td>12.5245</td>\n",
       "      <td>6.8083</td>\n",
       "      <td>12.7765</td>\n",
       "      <td>-16.7583</td>\n",
       "      <td>5.5475</td>\n",
       "      <td>10.9437</td>\n",
       "      <td>-5.0456</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9139</td>\n",
       "      <td>3.1889</td>\n",
       "      <td>2.7168</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>16.0791</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>5.8537</td>\n",
       "      <td>7.0612</td>\n",
       "      <td>20.1470</td>\n",
       "      <td>-1.3247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48763</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0822</td>\n",
       "      <td>1.7514</td>\n",
       "      <td>13.3706</td>\n",
       "      <td>6.2506</td>\n",
       "      <td>10.7307</td>\n",
       "      <td>-7.1566</td>\n",
       "      <td>6.8930</td>\n",
       "      <td>24.4839</td>\n",
       "      <td>4.8981</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2336</td>\n",
       "      <td>7.4945</td>\n",
       "      <td>2.6278</td>\n",
       "      <td>6.5365</td>\n",
       "      <td>16.4109</td>\n",
       "      <td>1.5065</td>\n",
       "      <td>1.8713</td>\n",
       "      <td>10.3388</td>\n",
       "      <td>17.3387</td>\n",
       "      <td>-15.6384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target    var_0   var_1    var_2   var_3    var_4    var_5   var_6  \\\n",
       "137312       0  12.8349 -1.8347   9.7758  6.3049  12.2757  -9.9022  6.8161   \n",
       "16192        0  12.7580  2.5818   9.6942  5.0552   9.7792  -0.0449  7.4387   \n",
       "22656        0   7.1304 -8.7134  11.5949  8.7937  12.5311  -3.4522  6.1531   \n",
       "63767        0  14.6030 -0.1394  12.5245  6.8083  12.7765 -16.7583  5.5475   \n",
       "48763        0   6.0822  1.7514  13.3706  6.2506  10.7307  -7.1566  6.8930   \n",
       "\n",
       "          var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "137312  15.2060  3.3815  ...  10.1672   6.2511   4.2107  12.0961  20.7002   \n",
       "16192   22.7764  1.5262  ...   3.2251  10.1442   1.3667   6.5912  19.6133   \n",
       "22656   17.0418  1.8732  ...  -3.9856   9.8221   1.8566   3.6718  15.3979   \n",
       "63767   10.9437 -5.0456  ...   8.9139   3.1889   2.7168   0.0079  16.0791   \n",
       "48763   24.4839  4.8981  ...   1.2336   7.4945   2.6278   6.5365  16.4109   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "137312   0.9548  -5.4146   9.8854  10.4776 -12.2150  \n",
       "16192   -0.4250   1.9741   9.9844  19.0760  13.4439  \n",
       "22656   -0.2740   4.8341   9.0588  16.6492  -8.0587  \n",
       "63767    0.8000   5.8537   7.0612  20.1470  -1.3247  \n",
       "48763    1.5065   1.8713  10.3388  17.3387 -15.6384  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ebdb",
   "metadata": {},
   "source": [
    "### Preparing X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2688b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = downsampled.drop(['target'], axis=1)\n",
    "y = downsampled['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6164dc5",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "The `Pipeline` class in scikit-learn is a convenient tool for chaining multiple steps together in a machine leeearning workflow.It allows to encapsulate preprocessing steps,feature engineering and model training into a single object.\n",
    "\n",
    "`GridSearchCv` is a utility provided by scikit learn that enables systematic parameter tuning for ML models.IT performs an exhaustive search over a predefined set of hyperparameter values, evaluating the model's performance using cross-vaidation.\n",
    "\n",
    "Here we are using `Logistic Regression` as our model. According to the steps defined in the pipeline , the model will first go through scaling using standard scaler and then Logistic Regression will be performed on the model.\n",
    "\n",
    "The data is then split into traininga nd testing set and Grid sEarch is performed . Thereafter using `.fit()` method the training dtaa is fit and finally using `.best_score_` the best cross validation score is calculated.`.best_params_`gives the best parameter value ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd83db77",
   "metadata": {},
   "source": [
    "#### MODEL 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cc9702c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7807252611147343 \n",
      " {'logreg__C': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"logreg\", LogisticRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Create the parameter space\n",
    "parameters = {\"logreg__C\": np.linspace(0.001, 1.0, 20)}\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6678dc7",
   "metadata": {},
   "source": [
    " Similary here we follow the similar steps and perform `KNeighborsClassifier`.It is a classification algorithm provided by scikit-learn that belongs to the family of instance-based learning  or lazy learning algorithms.It is a non-parametric algorithm, which means it does not make any assumptions about the underlying distribution of the data.Instead, it learns from the training  data by storing all of the training samples in memory and uses them to make predictions on new unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04202e3",
   "metadata": {},
   "source": [
    "#### MODEL 2: K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fe06a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5626943371696951 \n",
      " {'knn__n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"knn\", KNeighborsClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {\"knn__n_neighbors\": range(1, 10)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "# Instantiate the grid search object\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf7cdb2",
   "metadata": {},
   "source": [
    "### MODEL 3: Random Forest Classifier\n",
    "\n",
    "`RandomForestClassifier`:The Random forest classifier creates a set of decision trees from a randomly selected subset of the training set. It is basically a set of decision trees (DT) from a randomly selected subset of the training set and then it collects the votes from different decision trees to decide the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c6622af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664013086487946 \n",
      " {'rf__n_estimators': 13}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"rf\", RandomForestClassifier(criterion = 'entropy'))]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {\"rf__n_estimators\": range(1, 15)}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit to the training data\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, \"\\n\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feca2c3",
   "metadata": {},
   "source": [
    "### MODEL 4: Gaussian Naive Bayes\n",
    "\n",
    "`Naive Bayes` classifiers are a collection of classification algorithms based on Bayes’ Theorem. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.\n",
    "\n",
    "\n",
    " `confusion matrix`: A confusion matrix, also known as an error matrix, is a powerful tool used to evaluate the performance of classification models. The matrix is a tabular format that shows predicted values against their actual values.This allows us to understand whether the model is performing well or not.The rows represent the instances of the actual class, and\n",
    "The columns represent the instances of the predicted class.\n",
    "a confusion matrix is made up of four main components:\n",
    "\n",
    "   * True Positives (TP): instances where the model correctly predicted the positive class.\n",
    "   * True Negatives (TN): instances where the model correctly predicted the negative class.\n",
    "   * False Positives (FP): instances where the model incorrectly predicted the positive class (also known as Type I error).\n",
    "   * False Negatives (FN): instances where the model incorrectly predicted the negative class (also known as Type II error).\n",
    "   \n",
    "   \n",
    " `accuracy score`: One of the widely used metrics that computes the performance of classification models is accuracy. The percentage of labels that our model successfully predicted is represented by accuracy. For instance, if our model accurately classified 80 of 100 labels, its accuracy would be 0.80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a9dea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3258  772]\n",
      " [ 790 3220]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8057213930348258"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"gnb\", GaussianNB())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=21)\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cd9de9",
   "metadata": {},
   "source": [
    "### After comparing all the models we find that Gaussian Naive Bayes gives the best solution , so we predict the final model using Gaussian Naive Bayes algrithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d012870",
   "metadata": {},
   "source": [
    "### Final Model & Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0092fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [(\"scaler\", StandardScaler()),\n",
    "         (\"gnb\", GaussianNB())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "y_pred = pipeline.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a4bde9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5787a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output=pd.DataFrame({'ID_code': test.ID_code,\n",
    "                   'target': y_pred})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"The submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc6ff86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5ec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
