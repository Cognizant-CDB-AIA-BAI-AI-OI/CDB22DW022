{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFkZT-twHXVZ",
    "outputId": "e0454f72-788f-4bd2-d255-458fc0e112f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IabsmgtUHHVG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import json\n",
    "import re\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "In the dataset, we include the recipe id, the type of cuisine, and the list of ingredients of each recipe (of variable length). The data is stored in JSON format. \n",
    "\n",
    "An example of a recipe node in train.json:\n",
    "\n",
    " {\n",
    " \"id\": 24717,\n",
    " \"cuisine\": \"indian\",\n",
    " \"ingredients\": [\n",
    "     \"tumeric\",\n",
    "     \"vegetable stock\",\n",
    "     \"tomatoes\",\n",
    "     \"garam masala\",\n",
    "     \"naan\",\n",
    "     \"red lentils\",\n",
    "     \"red chili peppers\",\n",
    "     \"onions\",\n",
    "     \"spinach\",\n",
    "     \"sweet potatoes\"\n",
    " ]\n",
    " },\n",
    "In the test file test.json, the format of a recipe is the same as train.json, only the cuisine type is removed, as it is the target variable you are going to predict.\n",
    "\n",
    "# File descriptions\n",
    "train.json - the training set containing recipes id, type of cuisine, and list of ingredients\n",
    "test.json - the test set containing recipes id, and list of ingredients\n",
    "sample_submission.csv - a sample submission file in the correct format\n",
    "In the dataset, we include the recipe id, the type of cuisine, and the list of ingredients of each recipe (of variable length). The data is stored in JSON format. \n",
    "\n",
    "An example of a recipe node in train.json:\n",
    "\n",
    " {\n",
    " \"id\": 24717,\n",
    " \"cuisine\": \"indian\",\n",
    " \"ingredients\": [\n",
    "     \"tumeric\",\n",
    "     \"vegetable stock\",\n",
    "     \"tomatoes\",\n",
    "     \"garam masala\",\n",
    "     \"naan\",\n",
    "     \"red lentils\",\n",
    "     \"red chili peppers\",\n",
    "     \"onions\",\n",
    "     \"spinach\",\n",
    "     \"sweet potatoes\"\n",
    " ]\n",
    " },\n",
    "In the test file test.json, the format of a recipe is the same as train.json, only the cuisine type is removed, as it is the target variable you are going to predict.\n",
    "\n",
    "File descriptions\n",
    "train.json - the training set containing recipes id, type of cuisine, and list of ingredients\n",
    "test.json - the test set containing recipes id, and list of ingredients\n",
    "sample_submission.csv - a sample submission file in the correct format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DQQ_E3tEJgTX"
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('C:/Users/2211586/Downloads/whats-cooking-kernels-only/train.json')\n",
    "test = pd.read_json('C:/Users/2211586/Downloads/whats-cooking-kernels-only/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iSMFmOsvJytJ"
   },
   "outputs": [],
   "source": [
    "train['num_ingredients'] = train['ingredients'].apply(lambda x: len(x))\n",
    "test['num_ingredients'] = test['ingredients'].apply(lambda x: len(x))\n",
    "#train['num_ingredients_2'] = train['ingredients'].apply(lambda x: len(x)*len(x))\n",
    "#train['num_ingredients_log'] = train['ingredients'].apply(lambda x: log(len(x))\n",
    "train = train[train['num_ingredients'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "OkbXIMN6KAJ_",
    "outputId": "7a8e7761-9006-4128-a47d-e96c73f3eab5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor ingredient, expected in [\\n    (\\'eggs\\', \\'egg\\'),\\n    (\\'all-purpose flour\\', \\'all purpose flour\\'),\\n    (\\'purée\\', \\'purée\\'),\\n    (\\'1% low-fat milk\\', \\'lowfat milk\\'),\\n    (\\'half & half\\', \\'half half\\'),\\n    (\\'safetida (powder)\\', \\'safetida (powder)\\')\\n]:\\n    actual = preprocess([ingredient])\\n    assert actual == expected, f\\'\"{expected}\" is excpected but got \"{actual}\"\\'\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess(ingredients):\n",
    "    ingredients_text = ' '.join(ingredients)\n",
    "    ingredients_text = ingredients_text.lower()\n",
    "    ingredients_text = ingredients_text.replace('-', '')#wasabe\n",
    "    ingredients_text = ingredients_text.replace('wasabe', 'wasabi') #for wrong name\n",
    "    #ingredients_text = ingredients_text.replace('egg whites', 'eggwhites , egg , whites')\n",
    "    #ingredients_text = ingredients_text.replace('lime juice', 'limejuice')\n",
    "    #ingredients_text = ingredients_text.replace('clam juice', 'clamjuice')\n",
    "    #ingredients_text = ingredients_text.replace('lemon juice', 'lemonjuice')\n",
    "    #ingredients_text = ingredients_text.replace('orange juice', 'orangejuice')\n",
    "    #ingredients_text = ingredients_text.replace('soy sauce', 'soysauce')\n",
    "    ingredients_text = ingredients_text.replace('fish sauce', 'fishsauce')\n",
    "    #ingredients_text = ingredients_text.replace('sesame oil', 'sesameoil')\n",
    "    #ingredients_text = ingredients_text.replace('olive oil', 'oliveoil')#vegetable oil corn oil\n",
    "    #ingredients_text = ingredients_text.replace('vegetable oil', 'vegetableoil')\n",
    "    #ingredients_text = ingredients_text.replace('corn oil', 'cornoil')#rice wine\n",
    "    #\n",
    "    ingredients_text = ingredients_text.replace('coconut cream', 'coconutcream')\n",
    "    #\n",
    "    ingredients_text = ingredients_text.replace('yellow onion', 'yellowonion')\n",
    "    ingredients_text = ingredients_text.replace('cream cheese', 'creamcheese') \n",
    "    ingredients_text = ingredients_text.replace('baby spinach', 'babyspinach')\n",
    "    ingredients_text = ingredients_text.replace('coriander seeds', 'corianderseeds')\n",
    "    ingredients_text = ingredients_text.replace('corn tortillas', 'corntortillas')\n",
    "    ingredients_text = ingredients_text.replace('rice cakes', 'ricecakes')\n",
    "    words = []\n",
    "    for word in ingredients_text.split():\n",
    "        if re.findall('[0-9]', word): continue\n",
    "        if len(word) <= 2: continue\n",
    "        if '’' in word: continue\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        if len(word) > 0: words.append(word)\n",
    "    return ' '.join(words)\n",
    "'''\n",
    "for ingredient, expected in [\n",
    "    ('eggs', 'egg'),\n",
    "    ('all-purpose flour', 'all purpose flour'),\n",
    "    ('purée', 'purée'),\n",
    "    ('1% low-fat milk', 'lowfat milk'),\n",
    "    ('half & half', 'half half'),\n",
    "    ('safetida (powder)', 'safetida (powder)')\n",
    "]:\n",
    "    actual = preprocess([ingredient])\n",
    "    assert actual == expected, f'\"{expected}\" is excpected but got \"{actual}\"'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SoDoCj1sLgie",
    "outputId": "5d6261a5-566c-457c-aefd-f5687a0592df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\2211586\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "OWXNRCfGKCTt",
    "outputId": "9a17f068-e162-44f2-ec43-77a7070e3c16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 39559/39559 [00:08<00:00, 4864.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 9944/9944 [00:01<00:00, 5287.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>romaine lettuce black olive grape tomato garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>plain flour ground pepper salt tomato ground b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>egg pepper salt mayonaise cooking oil green ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>black pepper shallot cornflour cayenne pepper ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients                                                  x  \n",
       "0                9  romaine lettuce black olive grape tomato garli...  \n",
       "1               11  plain flour ground pepper salt tomato ground b...  \n",
       "2               12  egg pepper salt mayonaise cooking oil green ch...  \n",
       "3                4                     water vegetable oil wheat salt  \n",
       "4               20  black pepper shallot cornflour cayenne pepper ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['x'] = train['ingredients'].progress_apply(lambda ingredients: preprocess(ingredients))\n",
    "test['x'] = test['ingredients'].progress_apply(lambda ingredients: preprocess(ingredients))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-SoE8K2wKHcR"
   },
   "outputs": [],
   "source": [
    "vectorizer = make_pipeline(\n",
    "    TfidfVectorizer(sublinear_tf=True),\n",
    "    FunctionTransformer(lambda x: x.astype('float'), validate=False)\n",
    ")\n",
    "\n",
    "x_train = vectorizer.fit_transform(train['x'].values)\n",
    "x_train.sort_indices()\n",
    "x_test = vectorizer.transform(test['x'].values)\n",
    "\n",
    "#x_train = x_train.toarray()\n",
    "#x_test = x_test.toarray()\n",
    "#x_train = np.concatenate((train['num_ingredients'], x_train), axis = 1)\n",
    "#x_test = np.concatenate((test['num_ingredients'], x_test), axis = 1)\n",
    "\n",
    "#x_train = np.column_stack((train['num_ingredients'], x_train))\n",
    "#x_test = np.column_stack((test['num_ingredients'], x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkCeGj8PKKjs",
    "outputId": "32840747-e07b-422f-f8e9-72f7b848816a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazilian': 0,\n",
       " 'british': 1,\n",
       " 'cajun_creole': 2,\n",
       " 'chinese': 3,\n",
       " 'filipino': 4,\n",
       " 'french': 5,\n",
       " 'greek': 6,\n",
       " 'indian': 7,\n",
       " 'irish': 8,\n",
       " 'italian': 9,\n",
       " 'jamaican': 10,\n",
       " 'japanese': 11,\n",
       " 'korean': 12,\n",
       " 'mexican': 13,\n",
       " 'moroccan': 14,\n",
       " 'russian': 15,\n",
       " 'southern_us': 16,\n",
       " 'spanish': 17,\n",
       " 'thai': 18,\n",
       " 'vietnamese': 19}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train['cuisine'].values)\n",
    "dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_vpcYOxlKPsU"
   },
   "outputs": [],
   "source": [
    "estimator = SVC(C=250, # penalty parameter, setting it to a larger value \n",
    "\t \t\t\t kernel='rbf', # kernel type, rbf working fine here\n",
    "\t \t\t\t degree=3, # default value, not tuned yet\n",
    "\t \t\t\t gamma=1.4, # kernel coefficient, not tuned yet\n",
    "\t \t\t\t coef0=1, # change to 1 from default value of 0.0\n",
    "\t \t\t\t shrinking=True, # using shrinking heuristics\n",
    "\t \t\t\t tol=0.001, # stopping criterion tolerance \n",
    "\t \t\t\t probability=False, # no need to enable probability estimates\n",
    "\t \t\t\t cache_size=1000, # 200 MB cache size\n",
    "\t \t\t\t class_weight=None, # all classes are treated equally \n",
    "\t \t\t\t verbose=False, # print the logs \n",
    "\t \t\t\t max_iter=-1, # no limit, let it run\n",
    "\t \t\t\t decision_function_shape=None, # will use one vs rest explicitly \n",
    "\t \t\t\t random_state=None)\n",
    "classifier = OneVsRestClassifier(estimator, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g0h_Ox_wNtoB",
    "outputId": "b65853ab-9528-40ce-a3c7-b4270885f879"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8134179011588326"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(classifier, x_train, y_train, cv=3)\n",
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FkzH322OOvnp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=250, break_ties=False, cache_size=1000,\n",
       "                                  class_weight=None, coef0=1,\n",
       "                                  decision_function_shape=None, degree=3,\n",
       "                                  gamma=1.4, kernel='rbf', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False),\n",
       "                    n_jobs=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "iE8nTq57KYZC",
    "outputId": "9361e9c9-1e82-47aa-e029-6df8e255cf55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score on train data: 0.9996713769306605\n"
     ]
    }
   ],
   "source": [
    "y_pred = label_encoder.inverse_transform(classifier.predict(x_train))\n",
    "y_true = label_encoder.inverse_transform(y_train)\n",
    "\n",
    "print(f'accuracy score on train data: {accuracy_score(y_true, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "Bm_EmPzqKawh",
    "outputId": "3caba305-9166-4389-ebfe-e46fe01f4406"
   },
   "outputs": [],
   "source": [
    "def report2dict(cr):\n",
    "    rows = []\n",
    "    for row in cr.split(\"\\n\"):\n",
    "        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n",
    "        if len(parsed_row) > 0: rows.append(parsed_row)\n",
    "    measures = rows[0]\n",
    "    classes = defaultdict(dict)\n",
    "    for row in rows[1:]:\n",
    "        class_label = row[0]\n",
    "        for j, m in enumerate(measures):\n",
    "            classes[class_label][m.strip()] = float(row[j + 1].strip())\n",
    "    return classes\n",
    "report = classification_report(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "KSv1DgdSKjAT",
    "outputId": "7ad956e3-bc2f-4649-c215-c039927de2be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       cuisine\n",
       "0  18009         irish\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = label_encoder.inverse_transform(classifier.predict(x_test))\n",
    "test['cuisine'] = y_pred\n",
    "test[['id', 'cuisine']].to_csv('sample_submission.csv', index=False)\n",
    "test[['id', 'cuisine']].head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
